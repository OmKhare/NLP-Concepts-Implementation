{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "Ib7g_Adtuy7u",
        "outputId": "6d5b1521-e142-4489-f93d-cc969ad1b545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9928ebc8aaab458a80fbe5201b7cd4c5-0\" class=\"displacy\" width=\"575\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">John</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">saw</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Mary</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9928ebc8aaab458a80fbe5201b7cd4c5-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9928ebc8aaab458a80fbe5201b7cd4c5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9928ebc8aaab458a80fbe5201b7cd4c5-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9928ebc8aaab458a80fbe5201b7cd4c5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\tJohn\tJohn\tPROPN\tNNP\t_\t2\tnsubj\t_\t_\n",
            "2\tsaw\tsee\tVERB\tVBD\t_\t2\tROOT\t_\t_\n",
            "3\tMary\tMary\tPROPN\tNNP\t_\t2\tdobj\t_\t_\n",
            "\n",
            "Dependencies:\n",
            "John <--nsubj-- saw\n",
            "saw <--ROOT-- saw\n",
            "Mary <--dobj-- saw\n",
            "\n",
            "Transitions:\n",
            "SHIFT\n",
            "LEFT-ARC\n",
            "SHIFT\n",
            "RIGHT-ARC\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_694b3f17-143d-41ea-99e6-936fcf06b1bc\", \"dependency_parse_output.txt\", 116)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.parse.dependencygraph import DependencyGraph\n",
        "from nltk import Tree\n",
        "nltk.download('punkt')\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Load the English language model using spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define the input sentence\n",
        "sentence = \"John saw Mary\"\n",
        "\n",
        "# Parse the input sentence with spaCy\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# Render and display the dependency tree using spaCy's displacy\n",
        "displacy.render(doc, style='dep', jupyter=True)\n",
        "\n",
        "# Define a function to convert spaCy's parsed document into CoNLL format\n",
        "def spacy_to_conll(doc):\n",
        "    conll_format = \"\"\n",
        "    for token in doc:\n",
        "        head_id = token.head.i + 1 if token.head is not None else 0\n",
        "        conll_format += f\"{token.i+1}\\t{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.tag_}\\t_\\t{head_id}\\t{token.dep_}\\t_\\t_\\n\"\n",
        "    return conll_format\n",
        "\n",
        "# Convert the parsed document into CoNLL format\n",
        "conll_output = spacy_to_conll(doc)\n",
        "print(conll_output)\n",
        "\n",
        "# Constants for transition actions\n",
        "SHIFT = 'SHIFT'\n",
        "LEFT_ARC = 'LEFT-ARC'\n",
        "RIGHT_ARC = 'RIGHT-ARC'\n",
        "REDUCE = 'REDUCE'\n",
        "\n",
        "# Define a function to check if a reduction action is applicable\n",
        "def reduce(stack, buffer, dependencies):\n",
        "    if len(stack) > 1:\n",
        "        top_stack, second_stack = stack[-1], stack[-2]\n",
        "\n",
        "        if any(token[2] == top_stack[0] for token in stack[:-1]):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Define a function to determine the next transition action\n",
        "def oracle(stack, buffer, dependencies):\n",
        "    if len(stack) > 1:\n",
        "        top_stack, second_stack = stack[-1], stack[-2]\n",
        "\n",
        "        if second_stack and top_stack[0] == second_stack[2]:\n",
        "            return LEFT_ARC\n",
        "        elif top_stack and second_stack and top_stack[2] == second_stack[0]:\n",
        "            return RIGHT_ARC\n",
        "        elif reduce(stack, buffer, dependencies):\n",
        "            return REDUCE\n",
        "    if buffer:\n",
        "        return SHIFT\n",
        "    return None\n",
        "\n",
        "# Define a function to perform transition-based dependency parsing\n",
        "def transition_based_dependency_parse(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    stack = [(0, 'ROOT', None)]\n",
        "    buffer = [(i+1, token.text, token.head.i+1) for i, token in enumerate(doc)]\n",
        "    transitions = []\n",
        "    dependencies = []\n",
        "\n",
        "    first_shift_removed = False\n",
        "\n",
        "    while buffer or len(stack) > 1:\n",
        "        # Get the next transition action using the oracle\n",
        "        transition = oracle(stack, buffer, dependencies)\n",
        "        if transition is None:\n",
        "            break\n",
        "        if transition == SHIFT and not first_shift_removed:\n",
        "            first_shift_removed = True\n",
        "        else:\n",
        "            transitions.append(transition)\n",
        "        if transition == SHIFT and buffer:\n",
        "            stack.append(buffer.pop(0))\n",
        "        elif transition == LEFT_ARC and len(stack) > 1:\n",
        "            dependencies.append((stack[-2][1], stack[-1][1]))\n",
        "            stack.pop(-2)\n",
        "        elif transition == RIGHT_ARC and len(stack) > 1:\n",
        "            dependencies.append((stack[-1][1], stack[-2][1]))\n",
        "            stack.pop()\n",
        "        elif transition == REDUCE and len(stack) > 1:\n",
        "            stack.pop()\n",
        "\n",
        "    return dependencies, transitions\n",
        "\n",
        "# Example usage of the transition-based dependency parsing function\n",
        "dependencies, transitions = transition_based_dependency_parse(sentence)\n",
        "\n",
        "# Print the dependencies in a readable format\n",
        "print(\"Dependencies:\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text} <--{token.dep_}-- {token.head.text}\")\n",
        "\n",
        "# Print the transition actions\n",
        "print(\"\\nTransitions:\")\n",
        "for trans in transitions:\n",
        "    print(trans)\n",
        "\n",
        "# Save the output to a file\n",
        "from google.colab import files\n",
        "output_file_path = \"dependency_parse_output.txt\"\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    output_file.write(\"Dependencies:\\n\")\n",
        "    for token in doc:\n",
        "        output_file.write(f\"{token.text} <--{token.dep_}-- {token.head.text}\\n\")\n",
        "\n",
        "    output_file.write(\"\\nTransitions:\\n\")\n",
        "    for trans in transitions:\n",
        "        output_file.write(f\"{trans}\\n\")\n",
        "\n",
        "# Download the output file\n",
        "files.download(output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6n5Ny8ZA06bA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}